---
layout: post
title: "The Light Particles @ The End of The Tunnel"
author: Vinny Harris-Riviello
---

<center>

<img src = '{{ "/images/slide1.PNG" | relative_url }}' width="500">   

</center>

# All About The Data
The day ran short, but the energy was high. Before wrapping up the Bootcamp with our presentation. We had an hour to talk in our team 2 breakroom to finalize the details of the presentation on our chosen topic: Code Performance Assessment.
 


<center>

<img src = '{{ "/images/slideUsman.PNG" | relative_url }}' width="500">   

</center>

# Molecular Simulations
We separated the material into three topics. Usman's presentation described what Monte Carlo methods are, what they are used for and how you can leverage them beyond the lab or classroom. The Bootcamp used the Monte Carlo as a primary focus for us to learn to create simulations in three different versions. 
For us to do a systematic assessment of the performance of the three MC versions. We had to make some minor adjustments to the code so we could easily track the code speed by comparing different cases.  


<center>

<img src = '{{ "/images/slideKevn.PNG" | relative_url }}' width="500">   

</center>

# Programming and Data 
Kevin presented the data we gathered during the performance assessment. We decided to do some further investigation and ran a performance comparison, not only against the number of steps, but also: cutoff, temperature, maximum displacement, and a base case. As he showed today during the presentation the one condition that affected performance the most was the number of steps. From the three MC versions, c++ was significantly faster than both versions of Python. We did not run c++ with any optimization and yet it was able to outrun even the NumPy version over half the time.  

<center>

<img src = '{{ "/images/slideVinny.PNG" | relative_url }}' width="500">   

</center>

# Software Engineering
During the Bootcamp, we used important aspects of SWE, such as Version Control. VC facilitated our interaction as a team. It became particularly more important in our final project when we depended on the same source code. We also used testing, refactoring, and optimization. During our performance assessment Kevin noticed that our version of NumPy had not leveraged Numpy in some vectors in the run_simulation function, once he refactored that code, we ran all the Python assessment again on the same computer and we discovered that just by changing a few lines of code the NumPy could perform almost in half the time.   

<center>

<img src = '{{ "/images/performance.png" | relative_url }}' width="500">   

</center>